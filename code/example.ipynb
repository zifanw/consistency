{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "from consistency import IterativeSearch\n",
    "from consistency import PGDsL2\n",
    "from consistency import StableNeighborSearch\n",
    "\n",
    "from utils import load_dataset\n",
    "from utils import invalidation\n",
    "\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "gpu = 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[gpu], 'GPU')\n",
    "device = gpus[gpu]\n",
    "\n",
    "for device in tf.config.experimental.get_visible_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(X_train, y_train), (X_test, y_test), n_classes = load_dataset('Seizure', path_to_data_dir='dataset/data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8050, 178)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def dnn(input_shape, n_classes=2):\n",
    "    x = tf.keras.Input(input_shape)\n",
    "    y = tf.keras.layers.Dense(128)(x)\n",
    "    y = tf.keras.layers.Activation('relu')(y)\n",
    "    y = tf.keras.layers.Dense(128)(y)\n",
    "    y = tf.keras.layers.Activation('relu')(y)\n",
    "    y = tf.keras.layers.Dense(n_classes)(y)\n",
    "    y = tf.keras.layers.Activation('softmax')(y)\n",
    "    return tf.keras.models.Model(x, y)\n",
    "\n",
    "def train_dnn(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=0)\n",
    "    model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "baseline_model = dnn(X_train.shape[1:], n_classes=n_classes)\n",
    "baseline_model = train_dnn(baseline_model, X_train, y_train, X_test, y_test, batch_size=256)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14/14 [==============================] - 0s 737us/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9762\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model_1 = dnn(X_train.shape[1:], n_classes=n_classes)\n",
    "model_1 = train_dnn(baseline_model, X_train, y_train, X_test, y_test, batch_size=256)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14/14 [==============================] - 0s 697us/step - loss: 0.1947 - sparse_categorical_accuracy: 0.9730\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Robust Neighbor Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "sns_fn = StableNeighborSearch(baseline_model,\n",
    "                 clamp=[X_train.min(), X_train.max()],\n",
    "                 num_classes=2,\n",
    "                 sns_eps=0.1,\n",
    "                 sns_nb_iters=100,\n",
    "                 sns_eps_iter=1.e-3,\n",
    "                 n_interpolations=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "L1_iter_search = IterativeSearch(baseline_model,\n",
    "                                clamp=[X_train.min(), X_train.max()],\n",
    "                                num_classes=2,\n",
    "                                eps=0.3,\n",
    "                                nb_iters=40,\n",
    "                                eps_iter=0.01,\n",
    "                                norm=1,\n",
    "                                sns_fn=sns_fn)\n",
    "                                \n",
    "l1_cf, pred_cf, is_valid = L1_iter_search(X_test[:128])\n",
    "iv = invalidation(l1_cf,\n",
    "                np.argmax(baseline_model.predict(X_test[:128]), axis=1),\n",
    "                model_1,\n",
    "                affinity_set=[[0], [1]])\n",
    "\n",
    "print(f\"Invalidation Rate: {iv}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 4s 1s/step\n",
      "Invalidation Rate: (0.0,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "L2_iter_search = IterativeSearch(baseline_model,\n",
    "                                clamp=[X_train.min(), X_train.max()],\n",
    "                                num_classes=2,\n",
    "                                eps=0.3,\n",
    "                                nb_iters=40,\n",
    "                                eps_iter=0.01,\n",
    "                                norm=2,\n",
    "                                sns_fn=sns_fn)\n",
    "l2_cf, pred_cf, is_valid = L2_iter_search(X_test[:128])\n",
    "\n",
    "iv  = invalidation(l2_cf,\n",
    "                np.argmax(baseline_model.predict(X_test[:128]), axis=1),\n",
    "                model_1,\n",
    "                affinity_set=[[0], [1]])\n",
    "\n",
    "print(f\"Invalidation Rate: {iv}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4/4 [==============================] - 4s 981ms/step\n",
      "Invalidation Rate: (0.0,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "pgd_iter_search = PGDsL2(baseline_model,\n",
    "                        clamp=[X_train.min(), X_train.max()],\n",
    "                        num_classes=2,\n",
    "                        eps=2.0,\n",
    "                        nb_iters=100,\n",
    "                        eps_iter=0.04,\n",
    "                        sns_fn=sns_fn)\n",
    "pgd_cf, pred_cf, is_valid = pgd_iter_search(X_test[:128], num_interpolations=10, batch_size=64)\n",
    "\n",
    "iv = invalidation(pgd_cf,\n",
    "                np.argmax(baseline_model.predict(X_test[:128]), axis=1),\n",
    "                model_1,\n",
    "                batch_size=32,\n",
    "                affinity_set=[[0], [1]])\n",
    "\n",
    "print(f\"Invalidation Rate: {iv}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "111/111 [==============================] - 18s 164ms/step\n",
      "Invalidation Rate: (0.0,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('tf2': conda)"
  },
  "interpreter": {
   "hash": "21248d95275e884bc33c3f7011a493747d4a786160cbaad2c822a0cee53a1cdc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}